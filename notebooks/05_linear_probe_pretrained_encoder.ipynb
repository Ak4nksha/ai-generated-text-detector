{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIZefGOntfKjmNj1KxKzr1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ak4nksha/ai-generated-text-detector/blob/main/notebooks/05_linear_probe_pretrained_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Probe on a Pretrained Encoder\n",
        "\n",
        "Goal: Evaluate how well a **frozen pretrained text encoder** separates\n",
        "human-written vs LLM-generated text using a **linear classifier** on top.\n",
        "\n",
        "- Encoder is frozen (no fine-tuning).\n",
        "- Only a lightweight classifier is trained.\n",
        "- Uses the fixed `splits_v1` created in notebook 03.\n"
      ],
      "metadata": {
        "id": "yt5TFC4gIoiI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UM5ssqKQGT6h"
      },
      "outputs": [],
      "source": [
        "!pip -q install sentence-transformers scikit-learn pandas numpy tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "import json\n",
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "P-230c-GIvyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "Nblx3Ov5IwT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SPLITS_DIR = Path(\"/content/drive/MyDrive/artifacts/splits_v1\")\n",
        "\n",
        "train_df = pd.read_csv(SPLITS_DIR / \"train.csv\")\n",
        "val_df   = pd.read_csv(SPLITS_DIR / \"val.csv\")\n",
        "test_df  = pd.read_csv(SPLITS_DIR / \"test.csv\")\n",
        "\n",
        "for name, df in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n",
        "    if \"text\" not in df.columns or \"label\" not in df.columns:\n",
        "        raise ValueError(f\"{name}.csv must contain columns: text, label\")\n",
        "\n",
        "y_train = train_df[\"label\"].astype(int).values\n",
        "y_val   = val_df[\"label\"].astype(int).values\n",
        "y_test  = test_df[\"label\"].astype(int).values\n",
        "\n",
        "print(\"Loaded splits:\", len(train_df), len(val_df), len(test_df))"
      ],
      "metadata": {
        "id": "UMMCEQ3PIynw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "ENCODER_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "encoder = SentenceTransformer(ENCODER_NAME)\n",
        "encoder.max_seq_length = 256\n",
        "print(\"Loaded encoder:\", ENCODER_NAME)\n"
      ],
      "metadata": {
        "id": "YRI0ghhcI7QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cache embeddings so we don't re-encode every time\n",
        "CACHE_DIR = Path(\"/content/drive/MyDrive/artifacts/linear_probe/cache\")\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def embed_texts(texts, cache_path: Path, batch_size: int = 64):\n",
        "    if cache_path.exists():\n",
        "        return np.load(cache_path)\n",
        "    emb = encoder.encode(\n",
        "        texts,\n",
        "        batch_size=batch_size,\n",
        "        show_progress_bar=True,\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True\n",
        "    )\n",
        "    np.save(cache_path, emb)\n",
        "    return emb\n",
        "\n",
        "X_train = embed_texts(train_df[\"text\"].tolist(), CACHE_DIR / \"X_train.npy\")\n",
        "X_val   = embed_texts(val_df[\"text\"].tolist(),   CACHE_DIR / \"X_val.npy\")\n",
        "X_test  = embed_texts(test_df[\"text\"].tolist(),  CACHE_DIR / \"X_test.npy\")\n",
        "\n",
        "print(\" Embeddings shapes:\", X_train.shape, X_val.shape, X_test.shape)\n"
      ],
      "metadata": {
        "id": "YuoBDQU6JAUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "clf = LogisticRegression(max_iter=2000, n_jobs=-1)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "val_pred = clf.predict(X_val)\n",
        "val_prob = clf.predict_proba(X_val)[:, 1]\n",
        "\n",
        "test_pred = clf.predict(X_test)\n",
        "test_prob = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "val_acc = accuracy_score(y_val, val_pred)\n",
        "val_f1  = f1_score(y_val, val_pred)\n",
        "\n",
        "test_acc = accuracy_score(y_test, test_pred)\n",
        "test_f1  = f1_score(y_test, test_pred)\n",
        "\n",
        "print(\"VAL  acc/f1:\", val_acc, val_f1)\n",
        "print(\"TEST acc/f1:\", test_acc, test_f1)\n",
        "\n",
        "report = classification_report(y_test, test_pred, output_dict=True)\n"
      ],
      "metadata": {
        "id": "93tV9r6AJDEf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}